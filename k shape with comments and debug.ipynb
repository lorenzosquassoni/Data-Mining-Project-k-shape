{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-shape algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import multiprocessing\n",
    "from numpy.random import randint\n",
    "from numpy.linalg import norm, eigh\n",
    "from numpy.fft import fft, ifft\n",
    "from sklearn.base import ClusterMixin, BaseEstimator\n",
    "from sklearn.metrics import rand_score, normalized_mutual_info_score, adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Z-score*** Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-score is a mathematical approach to convert a \"Generic\" Random Variables to a Normal Random Variables. \n",
    "\n",
    "For more information about this approach: \n",
    "https://it.wikipedia.org/wiki/Standardizzazione_(statistica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Inputs**\n",
    "1. ```a```: numpy array containing time-series values;\n",
    "2. ```axis```: axis used to evaluate mean and standard deviation. For axis we intend rows or columns.\n",
    "3. ```ddof```: Degrees of freedom correction in the calculation of the standard deviation. Default value equals to 0\n",
    "\n",
    "**Function returned values**:\n",
    "1. Normalized Time-Series\n",
    "\n",
    "**Function Assumptions**:\n",
    "1. ```axis = 0 ```: normalize always on column axis. This is true beacuse we want to normalize time instants values, to exlude possible outliers or errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(a, axis=0, ddof=0):\n",
    "    a = np.asanyarray(a) #convert the input a in an array\n",
    "    mns = a.mean(axis=axis) #compute the mean of the time series along the column axis (mean for each time instant)\n",
    "    sstd = a.std(axis=axis, ddof=ddof) #compute the standard deviation of the array along the column axis (mean for each time instant)\n",
    "\n",
    "    ## If Condition-->\n",
    "    ## If axis equals to row (axis = 1) and dimensions of mean array is lower than dimensions of time series array\n",
    "    ## -----> calculate Z score expanding dimensions of mean and std array on row axis\n",
    "    ## If axis equals to columns (axis = 0) or dimensions of mean array is equal to dimensions of time series array\n",
    "    ## -----> calculate Z score as time-series array minus its mean, divided by standard deviation\n",
    "\n",
    "    if axis and mns.ndim < a.ndim:\n",
    "        res = ((a - np.expand_dims(mns, axis=axis)) / #compute normalized data and expand the the mean and sd to match the dimension with the array a (the mean and std have 1 dimension less=\n",
    "               np.expand_dims(sstd, axis=axis))\n",
    "    else:\n",
    "        res = (a - mns) / sstd #compute normalized data\n",
    "\n",
    "    ## nan_to_num method --> replace NaN values with 0 or large integer values for infinite values\n",
    "    return np.nan_to_num(res)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Roll_zeropad*** Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```roll_zeropad``` is a custom function to shift time series values to the right. The number of positions required by the movement are evaluated with parameter ```shift```.\n",
    "For each shift, a zero value is included in the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Inputs**\n",
    "1. ```a```: numpy array containing time-series values;\n",
    "2. ```shift```: Number of right movements required;\n",
    "3. ```axis```: axis to consider for right movements.\n",
    "\n",
    "**Function returned values**:\n",
    "1. Shifted Time-Series\n",
    "\n",
    "**Function Assumptions**:\n",
    "1. ```axis = None ```: time series can be considered as a 1D array and not as a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_zeropad(a, shift, axis=None):\n",
    "    # asanyarray method --> Convert the input to an ndarray, but pass ndarray subclasses through.\n",
    "    a = np.asanyarray(a) # Ensure that the input is ndarrary data type\n",
    "\n",
    "    # If no shift is required (shift = 0), it returns the original values of time series\n",
    "    if shift == 0:\n",
    "        return a\n",
    "\n",
    "    # If axis parameter is not evaluated (axis = None)\n",
    "    # ------> consider all elements of time series and not a specific dimensions, but this requires a reshape of data at the end\n",
    "    # If axis is set\n",
    "    # ------> extracted dimensions of a specific axis (rows or columns) and work on that\n",
    "    if axis is None:\n",
    "        n = a.size\n",
    "        reshape = True\n",
    "    else:\n",
    "        n = a.shape[axis]\n",
    "        reshape = False\n",
    "\n",
    "    # zeros_like() method --> Return an array of zeros with the same shape and type as a given array.\n",
    "\n",
    "    # If shift parameter is greater than size of the time series (but this requires that no axis are specified)\n",
    "    # ------> it evaluates an array of 0 values with the same size of a\n",
    "    if np.abs(shift) > n:\n",
    "        res = np.zeros_like(a)\n",
    "    # If shift parameter is lower than 0 (moving to the left)\n",
    "    # ------> subtract the shift value to n size of the array\n",
    "    # ------> extract the indices from 0 to (n-shift) values, considering a plain array (axis = None) or a specific dimensions\n",
    "    # ------> generate a 0-valued array with size [0, (n-shift)]\n",
    "    # ------> extract values from (n-shift) position to n position\n",
    "    # ------> create an array with values in range [(n-shift),n] at the beginning and all 0 values after\n",
    "    elif shift < 0:\n",
    "        shift += n\n",
    "        zeros = np.zeros_like(a.take(np.arange(n-shift), axis))\n",
    "        res = np.concatenate((a.take(np.arange(n-shift, n), axis), zeros), axis)\n",
    "    # If shift parameter is in the range [0, size of time series]\n",
    "    # ------> extract values from (n-shift) position to n position\n",
    "    # ------> generate a 0-valued array with size [(n-shift), n]\n",
    "    # ------> extract the indices from 0 to (n-shift) values, considering a plain array (axis = None) or a specific dimensions\n",
    "    # ------> create an array with 0 value at the beginning and then values in range [0, (n-shift)]\n",
    "    else:\n",
    "        zeros = np.zeros_like(a.take(np.arange(n-shift, n), axis))\n",
    "        res = np.concatenate((zeros, a.take(np.arange(n-shift), axis)), axis)\n",
    "\n",
    "    # If reshape is required\n",
    "    # -----> change shape (row, column) of shifted array, considering shape of time series values\n",
    "    if reshape:\n",
    "        return res.reshape(a.shape)\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***_ncc_c_3dim*** Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```_ncc_c_3dim``` is a custom function to evaluate the **array** of NCCc values. \\\n",
    "Each element of the array is associated with a specific shift computed on a specific time series.\\\n",
    "NCCc is a normalization of Cross Correlation value, which represents with a value the similarity between 2 time series\\\n",
    "K-Shape Algorithm uses NCCc to evaluate SBD distance measure which is used to assign the time series to the closest cluster centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Inputs**\n",
    "1. ```data```: numpy array containing 2 time series to compare;\n",
    "    * Generally, in the algorithm, X is the cluster centroid while Y is the time series to assign.\n",
    "\n",
    "**Function returned values**:\n",
    "1. The optimal value of NCCc between X and Y.\n",
    "\n",
    "**Function Assumptions**:\n",
    "1. ```None ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ncc_c_3dim(data):\n",
    "    # Extract X and Y from data\n",
    "    # Positions in data array are very important\n",
    "    x, y = data[0], data[1]\n",
    "\n",
    "    # np.norm function returns one of the eight matrix norms (X parameter considered is a 2D matrix.)\n",
    "    # Evaluating axis parameter specifies in which dimension evaluate matrix norm.\n",
    "    den = norm(x, axis=(0,1)) * norm(y, axis=(0,1))\n",
    "    #print(den)\n",
    "\n",
    "    # If the computed denominator of NCCc is so small, it is set to infinite value, in order to ignore NCCc value. \n",
    "    if den < 1e-9:\n",
    "        den = np.inf\n",
    "\n",
    "    # the variable represents the number of time instants considered for each time series.\n",
    "    x_len = x.shape[0]\n",
    "    #print(x_len)\n",
    "\n",
    "    # This is operation is necessary to improve computational effort of FFT.\n",
    "    # As the article said, in order to improve FFT performances, Cross Correlation must be an exact power-of-two.\n",
    "    # The following line of code approximate the result to the next power-of-two value. \n",
    "    fft_size = 1 << (2*x_len-1).bit_length()\n",
    "\n",
    "    # As the paper said, CC can be evaluated as convolution of two time series where one of two sequences is reversed in time domain. \n",
    "    # The convolution is computed as Inverse Discrete Fourier Transformer (IDFT) of the product of the individual Discrete Fourier Transforms (DFT) of the time series\n",
    "    # To reduce computational effort, Fast Fourier Transformer (FFT) substitutes DFT.\n",
    "    # np.conj function return the complex coniugate of a specified number. \n",
    "    # The complex conjugate of a complex number is obtained by changing the sign of its imaginary part.\n",
    "    cc = ifft(fft(x, fft_size, axis=0) * np.conj(fft(y, fft_size, axis=0)), axis=0)\n",
    "\n",
    "    # CC is the join, along axis 0 (rows), of two selected sequences\n",
    "    # The selected sequences are extracted from convolution of two time series (IFFT)\n",
    "    # CC is an array of complex numbers\n",
    "    cc = np.concatenate((cc[-(x_len-1):], cc[:x_len]), axis=0)\n",
    "    #print(cc)\n",
    "    \n",
    "    # Return array of NCCc values\n",
    "    return np.real(cc).sum(axis=-1) / den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***_sbd*** Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```_sbd``` function is used to evaluate Shape Based Distance between two time series\\\n",
    "In particular, SBD is similarity measures applied to two time series.\\\n",
    "SBD values are in range [0,2] with 0 assigning perfect match\\\n",
    "```_sbd``` function does not return similarity value, but it returns the optimal shift y.\\\n",
    "The optimal shift of Y represents the closest shift of Y compared to X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Inputs**\n",
    "1. ```x```: reference time series\n",
    "    * Generally, in the algorithm, X is the cluster centroid.\n",
    "2. ```y```: compared time series\n",
    "    * Generally, in the algorithm, X is the cluster centroid.\n",
    "\n",
    "**Function returned values**:\n",
    "1. The optimal shift of Y.\n",
    "\n",
    "**Function Assumptions**:\n",
    "1. ```None ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible that the algorithm can ignore this function\n",
    "# In fact, if cluster centroids are evaluated as all zeros, the function is not used\n",
    "def _sbd(x, y):\n",
    "    # Evaluate NCCc array\n",
    "    ncc = _ncc_c_3dim([x, y])\n",
    "    #print(ncc)\n",
    "\n",
    "    # Find the index where NCCc is maximized (w in the paper)\n",
    "    idx = np.argmax(ncc)\n",
    "    #print(ncc[idx])\n",
    "\n",
    "    # The position w is used to evaluate the optimal shift as w-m\n",
    "    # The shift index is passed to roll_zeropad function to generate optimal y shift\n",
    "    yshift = roll_zeropad(y, (idx + 1) - max(len(x), len(y)))\n",
    "    \n",
    "    return yshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***collect_shift*** Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Inputs**\n",
    "1. ```x```: reference time series\n",
    "    * Generally, in the algorithm, X is the cluster centroid.\n",
    "2. ```y```: compared time series\n",
    "    * Generally, in the algorithm, X is the cluster centroid.\n",
    "\n",
    "**Function returned values**:\n",
    "1. The optimal shift of Y.\n",
    "\n",
    "**Function Assumptions**:\n",
    "1. ```None ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_shift(data):\n",
    "    x, cur_center = data[0], data[1]\n",
    "    if np.all(cur_center==0):\n",
    "        return x\n",
    "    else:\n",
    "        return _sbd(cur_center, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_shape(idx, x, j, cur_center):\n",
    "    _a=[]\n",
    "    for i in range(len(idx)):\n",
    "        if idx[i] == j:\n",
    "            _a.append(collect_shift([x[i], cur_center]))\n",
    "\n",
    "    a = np.array(_a)\n",
    "    \n",
    "    if len(a) == 0:\n",
    "        indices = np.random.choice(x.shape[0], 1)\n",
    "        return np.squeeze(x[indices].copy())\n",
    "        #return np.zeros((x.shape[1]))\n",
    "\n",
    "    columns = a.shape[1]\n",
    "    y = zscore(a, axis=1, ddof=1)\n",
    "\n",
    "    s = np.dot(y[:, :, 0].transpose(), y[:, :, 0])\n",
    "    p = np.empty((columns, columns))\n",
    "    p.fill(1.0/columns)\n",
    "    p = np.eye(columns) - p\n",
    "    m = np.dot(np.dot(p, s), p)\n",
    "\n",
    "    _, vec = eigh(m)\n",
    "    centroid = vec[:, -1]\n",
    "\n",
    "    finddistance1 = np.sum(np.linalg.norm(a - centroid.reshape((x.shape[1], 1)), axis=(1, 2)))\n",
    "    finddistance2 = np.sum(np.linalg.norm(a + centroid.reshape((x.shape[1], 1)), axis=(1, 2)))\n",
    "\n",
    "    if finddistance1 >= finddistance2:\n",
    "        centroid *= -1\n",
    "\n",
    "    return zscore(centroid, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _kshape(x, k, centroid_init='zero', max_iter=100, n_jobs=1):\n",
    "    m = x.shape[0]\n",
    "    idx = randint(0, k, size=m)\n",
    "    if centroid_init == 'zero':\n",
    "        centroids = np.zeros((k, x.shape[1], x.shape[2]))\n",
    "    elif centroid_init == 'random':\n",
    "        indices = np.random.choice(x.shape[0], k)\n",
    "        centroids = x[indices].copy()\n",
    "    distances = np.empty((m, k))\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        old_idx = idx\n",
    "\n",
    "        for j in range(k):\n",
    "            for d in range(x.shape[2]):\n",
    "                centroids[j, :, d] = _extract_shape(idx, np.expand_dims(x[:, :, d], axis=2), j, np.expand_dims(centroids[j, :, d], axis=1))\n",
    "                #centroids[j] = np.expand_dims(_extract_shape(idx, x, j, centroids[j]), axis=1)\n",
    "\n",
    "        pool = multiprocessing.Pool(n_jobs)\n",
    "        args = []\n",
    "        for p in range(m):\n",
    "            for q in range(k):\n",
    "                args.append([x[p, :], centroids[q, :]])\n",
    "        result = pool.map(_ncc_c_3dim, args)\n",
    "        pool.close()\n",
    "        r = 0\n",
    "        for p in range(m):\n",
    "            for q in range(k):\n",
    "                distances[p, q] = 1 - result[r].max()\n",
    "                r = r + 1\n",
    "\n",
    "        idx = distances.argmin(1)\n",
    "        if np.array_equal(old_idx, idx):\n",
    "            break\n",
    "\n",
    "    return idx, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kshape(x, k, centroid_init='zero', max_iter=100):\n",
    "    idx, centroids = _kshape(np.array(x), k, centroid_init=centroid_init, max_iter=max_iter)\n",
    "    clusters = []\n",
    "    for i, centroid in enumerate(centroids):\n",
    "        series = []\n",
    "        for j, val in enumerate(idx):\n",
    "            if i == val:\n",
    "                series.append(j)\n",
    "        clusters.append((centroid, series))\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KShapeClusteringCPU(ClusterMixin,BaseEstimator):\n",
    "    labels_= None\n",
    "    centroids_ = None\n",
    "\n",
    "    def __init__(self,n_clusters, centroid_init='zero', max_iter=100, n_jobs=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.centroid_init = centroid_init\n",
    "        self.max_iter = max_iter\n",
    "        if n_jobs is None:\n",
    "            self.n_jobs=1\n",
    "        elif n_jobs == -1:\n",
    "            self.n_jobs = multiprocessing.cpu_count()\n",
    "        else:\n",
    "            self.n_jobs=n_jobs\n",
    "        \n",
    "\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        clusters = self._fit(X,self.n_clusters, self.centroid_init, self.max_iter,self.n_jobs)\n",
    "        self.labels_ = np.zeros(X.shape[0])\n",
    "        self.centroids_ =np.zeros((self.n_clusters, X.shape[1], X.shape[2]))\n",
    "        for i in range(self.n_clusters):\n",
    "            self.labels_[clusters[i][1]] = i\n",
    "            self.centroids_[i]=clusters[i][0]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        labels, _ = self._predict(X,self.centroids_)\n",
    "        return labels\n",
    "        \n",
    "    \n",
    "    def _predict(self,x, centroids):\n",
    "        m = x.shape[0]\n",
    "        idx = randint(0, self.n_clusters, size=m)\n",
    "        distances = np.empty((m, self.n_clusters))\n",
    "        \n",
    "\n",
    "    \n",
    "        pool = multiprocessing.Pool(self.n_jobs)\n",
    "        args = []\n",
    "        for p in range(m):\n",
    "            for q in range(self.n_clusters):\n",
    "                args.append([x[p, :], centroids[q, :]])\n",
    "        result = pool.map(_ncc_c_3dim, args)\n",
    "        pool.close()\n",
    "        r = 0\n",
    "        for p in range(m):\n",
    "            for q in range(self.n_clusters):\n",
    "                distances[p, q] = 1 - result[r].max()\n",
    "                r = r + 1\n",
    "    \n",
    "        idx = distances.argmin(1)\n",
    "\n",
    "        return idx, centroids\n",
    "    \n",
    "    \n",
    "    def _fit(self,x, k, centroid_init='zero', max_iter=100,n_jobs=1):\n",
    "        idx, centroids = _kshape(np.array(x), k, centroid_init=centroid_init, max_iter=max_iter, n_jobs=n_jobs)\n",
    "        clusters = []\n",
    "        for i, centroid in enumerate(centroids):\n",
    "            series = []\n",
    "            for j, val in enumerate(idx):\n",
    "                if i == val:\n",
    "                    series.append(j)\n",
    "            clusters.append((centroid, series))\n",
    "    \n",
    "        return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```ClusterDataLoader``` class is used to read dataset input files and convert them in a set of arrays. \\\n",
    "The function will load every files (both TRAIN and TEST files) in a specific path. \\\n",
    "Every files must be a CSV files with comma separator\\\n",
    "\\\n",
    "Each row of the file represents a time-series and it contains:\n",
    "* The first element is cluster which time-series joins;\n",
    "* All successive elements are measurements of each time-series. Each measurements is associated with a specific time instants. \n",
    "\n",
    "It is important to highlight that there aren't any information about time-series or time instants order. \\\n",
    "We suppose that the order of time-series is not important for K-shape Clustering Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterDataLoader:\n",
    "    def __init__(self, dataset_path):\n",
    "        self.path = dataset_path\n",
    "\n",
    "    def load(self, sub_dataset_name):\n",
    "        ts, labels = [], []\n",
    "        for mode in ['_TRAIN']:\n",
    "            with open(os.path.join(self.path, sub_dataset_name, sub_dataset_name + mode)) as csv_file:\n",
    "                lines = csv.reader(csv_file, delimiter=',')\n",
    "                for line in lines:\n",
    "                    ts.append([float(x) for x in line[1:]])\n",
    "                    labels.append(int(line[0])-1)\n",
    "\n",
    "        if min(labels) == 1:\n",
    "            labels = labels - 1\n",
    "        if min(labels) == -1:\n",
    "            labels = labels + 1\n",
    "\n",
    "        return np.array(ts), np.array(labels), int(len(set(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Shape Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a subset (100 hundred rows) of ```CROP``` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'dataset/univariate_example/'\n",
    "DATASET_NAME = 'Crop'\n",
    "\n",
    "dataloder = ClusterDataLoader(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts, labels, num_clusters = dataloder.load(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Timeseries Dataset\n",
      "-------------------------\n",
      "\n",
      "[[-1.04911634 -0.96685745 -0.88459857 ... -0.51685297 -0.59911186\n",
      "  -0.68137074]\n",
      " [-1.10145498 -1.1413895  -1.18132403 ... -1.02158593 -1.10544843\n",
      "  -1.18931093]\n",
      " [-0.80873226 -0.98601697 -1.16330168 ... -0.78711217 -0.70063182\n",
      "  -0.61415147]\n",
      " ...\n",
      " [-1.62102196 -1.41436412 -1.20770628 ... -1.28672251 -0.75184341\n",
      "  -0.2169643 ]\n",
      " [-1.0246006  -1.48431623 -1.36938732 ... -1.04614977 -0.39967465\n",
      "   0.24680046]\n",
      " [-1.10748362 -1.14969269 -1.19190177 ... -0.67695102 -0.19154663\n",
      "   0.29385776]]\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------\\nTimeseries Dataset\\n-------------------------\\n\")\n",
    "print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Timeseries Dataset Dimensions\n",
      "-------------------------\n",
      "\n",
      "(100, 46)\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------\\nTimeseries Dataset Dimensions\\n-------------------------\\n\")\n",
    "print(ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Clusters Dataset\n",
      "-------------------------\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------\\nClusters Dataset\\n-------------------------\\n\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Clusters Dataset Dimensions\n",
      "-------------------------\n",
      "\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------\\nClusters Dataset Dimensions\\n-------------------------\\n\")\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(num_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Shape Single Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Execution time: 0.1790626049041748\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ksc = KShapeClusteringCPU(n_clusters=num_clusters,max_iter=2,n_jobs=-1)\n",
    "ksc.fit(np.expand_dims(ts, axis=2))\n",
    "print(f' Execution time: {time.time() - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monovariate Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monovariate time-series can be represented as a matrix NxM with:\n",
    "- N (rows) as the number of time-series. Each row represent a time series which can be connected to a specific date \n",
    "- M (columns) as time instants considered for each time series. Each time instants respects a frequency of analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of monovariate array of time series: 4 time series and 3 time instants\n",
    "##\n",
    "a_monovariate = np.array([[10, 12, 31],\n",
    "              [4, 9, 10],\n",
    "              [70, 81, 2],\n",
    "              [12, 112, 12]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate time-series can be represented as a matrix NxM with:\n",
    "- N (rows) as the number of time-series. Each row represent a time series which can be connected to a specific date \n",
    "- M (columns) as time instants considered for each time series. Each time instants respects a frequency of analysis \n",
    "\n",
    "The main difference with monovariate time-series is that each cell of the matrix is an array of values. The number of elements of the array can be considered as the number of variables involved, in addition to timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean\n",
      "-----------\n",
      "[[ 24.33333333 353.06666667]\n",
      " [ 12.33333333  14.70366667]\n",
      " [153.33333333  65.66666667]]\n",
      "Std\n",
      "-----------\n",
      "[[ 14.81740718 458.080352  ]\n",
      " [  9.84321537  12.21227362]\n",
      " [139.30382463  19.43078886]]\n"
     ]
    }
   ],
   "source": [
    "#Example of multivariate array of time series:\n",
    "\n",
    "#2 time series, with 3 time instants and 2 variables\n",
    "\n",
    "a_multivariate = np.array([[[11, 1000], [25, 30], [350, 40]],\n",
    "                           [[45, 0.2], [1, 0.111], [65, 70]],\n",
    "                           [[17, 59], [11, 14], [45, 87]]])\n",
    "\n",
    "#compute the mean for each time instant\n",
    "print(\"Mean\\n-----------\")\n",
    "print(a_multivariate.mean(axis=0))\n",
    "print(\"Std\\n-----------\")\n",
    "print(a_multivariate.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output can be explained as:\n",
    "- Cell 0,0 ==> mean (or std) of first elements of first time instant;\n",
    "- Cell 0,1 ==> mean (or std) of second elements of first time instant;\n",
    "- Cell 1,0 ==> mean (or std) of first elements of second time instant;\n",
    "....\n",
    "\n",
    "So the output is a matrix Nx(M-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Time Series - zScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.89984254  1.41227042]\n",
      "  [ 1.28684238  1.25253772]\n",
      "  [ 1.41178225 -1.32092767]]\n",
      "\n",
      " [[ 1.39475594 -0.77031609]\n",
      "  [-1.15138528 -1.19491809]\n",
      "  [-0.63410559  0.22301376]]\n",
      "\n",
      " [[-0.4949134  -0.64195433]\n",
      "  [-0.13545709 -0.05761963]\n",
      "  [-0.77767666  1.09791391]]]\n"
     ]
    }
   ],
   "source": [
    "#we apply the zscore function\n",
    "zscore_result = zscore(a_multivariate)\n",
    "print(zscore_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monovariate Time Series - zScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.52393683 -0.93494794  1.62139887]\n",
      " [-0.74848119 -1.00253454 -0.35247801]\n",
      " [ 1.72150673  0.61954382 -1.10443111]\n",
      " [-0.44908871  1.31793866 -0.16448974]]\n"
     ]
    }
   ],
   "source": [
    "#we apply the zscore function\n",
    "zscore_result = zscore(a_monovariate, axis=0)\n",
    "print(zscore_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monovariate Time Series - Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  12  31]\n",
      " [  4   9  10]\n",
      " [ 70  81   2]\n",
      " [ 12 112  12]]\n"
     ]
    }
   ],
   "source": [
    "print(a_monovariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  10  12]\n",
      " [ 31   4   9]\n",
      " [ 10  70  81]\n",
      " [  2  12 112]]\n"
     ]
    }
   ],
   "source": [
    "a_monovariate_shifted = roll_zeropad(a_monovariate, 1)\n",
    "print(a_monovariate_shifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating parameter ```shift``` to 1, the function shifts time series to the right of one position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12  31   4]\n",
      " [  9  10  70]\n",
      " [ 81   2  12]\n",
      " [112  12   0]]\n"
     ]
    }
   ],
   "source": [
    "a_monovariate_shifted = roll_zeropad(a_monovariate, -1)\n",
    "print(a_monovariate_shifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating parameter ```shift``` to -1, the function shifts time series to the left of one position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0]\n",
      " [ 0  0 10]\n",
      " [12 31  4]\n",
      " [ 9 10 70]]\n"
     ]
    }
   ],
   "source": [
    "a_monovariate_shifted = roll_zeropad(a_monovariate, 5)\n",
    "print(a_monovariate_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4   9  10]\n",
      " [ 70  81   2]\n",
      " [ 12 112  12]\n",
      " [  0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "a_monovariate_shifted = roll_zeropad(a_monovariate, -3)\n",
    "print(a_monovariate_shifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Time Series - Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.10e+01 1.00e+03]\n",
      "  [2.50e+01 3.00e+01]\n",
      "  [3.50e+02 4.00e+01]]\n",
      "\n",
      " [[4.50e+01 2.00e-01]\n",
      "  [1.00e+00 1.11e-01]\n",
      "  [6.50e+01 7.00e+01]]\n",
      "\n",
      " [[1.70e+01 5.90e+01]\n",
      "  [1.10e+01 1.40e+01]\n",
      "  [4.50e+01 8.70e+01]]]\n"
     ]
    }
   ],
   "source": [
    "print(a_multivariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.00e+00 1.10e+01]\n",
      "  [1.00e+03 2.50e+01]\n",
      "  [3.00e+01 3.50e+02]]\n",
      "\n",
      " [[4.00e+01 4.50e+01]\n",
      "  [2.00e-01 1.00e+00]\n",
      "  [1.11e-01 6.50e+01]]\n",
      "\n",
      " [[7.00e+01 1.70e+01]\n",
      "  [5.90e+01 1.10e+01]\n",
      "  [1.40e+01 4.50e+01]]]\n"
     ]
    }
   ],
   "source": [
    "a_multivariate_shifted = roll_zeropad(a_multivariate, 1)\n",
    "print(a_multivariate_shifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shifting works across the same row. Considering that each element of row has an array of values, which indexes means different variables to analyze (temp, humidity, etc), this can generate misunderstanding data because the operation changes the variable associated to data value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monovariate Time Series - NCCc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[2,5]])\n",
    "y = np.array([[2,5]])\n",
    "\n",
    "nccc = _ncc_c_3dim([x,y])\n",
    "\n",
    "print(nccc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBD: [[2 5]]\n"
     ]
    }
   ],
   "source": [
    "sbd = _sbd(x,y)\n",
    "\n",
    "print(f\"SBD: {sbd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599\n"
     ]
    }
   ],
   "source": [
    "x_len = 300\n",
    "xlen_trans = 2*x_len-1\n",
    "print(xlen_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(xlen_trans.bit_length())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "print (1 << xlen_trans.bit_length())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "print(2 ** 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.+0.j -3.+0.j]\n"
     ]
    }
   ],
   "source": [
    "print(fft([2,5],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.zeros((2, 2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
